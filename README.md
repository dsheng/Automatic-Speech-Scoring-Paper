# Automatic-Speech-Scoring-Paper
A list of papers on automatic speech scoring.

* [Impact of ASR Performance on Free Speaking Language Assessment](http://mi.eng.cam.ac.uk/~ar527/knill_is2018.pdf), K.M.Knill, *Interspeech 2018* :star::star::star:

This paper considered the impact of ASR performance on assessment of free speaking tests of non-native learners of English. Comparison of 2 state-of-the-art ASR systems with a significant difference in WER showed that the baseline auto-marking system based on audio and fluency related features was unaffected by the reduction in WER due to the system having been designed to mitigate ASR errors. The impact that ASR errors may have on the ability of the system to provide detailed feedback to the learner was also analysed.
* [Neural Approaches to Automated Speech Scoring of Monologue and Dialogue Responses](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8683717), Yao Qian et al, *Interspeech 2019*:star::star:

This paper presented Neural Network (NN) approaches (attention, BLSTM-RNN, encoder, MemN2N, and conditional inputs) to the automated assessment of non-native spontaneous speech in a monologic task and a simulated dialogic task. Three attention-based Bidirectional Long Short-Term Memory (BLSTM) Recurrent Neural Networks (RNN) are employed to learn three dimensions (i.e., delivery, language use, and content) of scoring rubrics for the spoken responses. The three subscores are fused together to generate a holistic score. The experimental results show that the NN approaches significantly outperform the conventional approaches to speech scoring and the correlations of automatically predicted scores with the reference human scores are higher than human-human agreement levels for both tasks.
